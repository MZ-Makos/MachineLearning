{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PYTORCH_TUTORIAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MZ-Makos/MachineLearning/blob/master/PYTORCH_TUTORIAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHnQTYUwoh3l",
        "colab_type": "text"
      },
      "source": [
        "# **What is Pytorch?**\n",
        "\n",
        "Pytorch is a python-based scientific computing package targeted for\n",
        "\n",
        "1.   replacement for NumPy to use the power of GPUs\n",
        "2.   deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **What is a Tensor?**\n",
        "\n",
        "Similar to NumPyâ€™s ndarrays, but can also be used on a GPU to accelerate computing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_FbK8f7pWPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0bb20dbe-d684-4720-e709-a9f34ab4e45d"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9585, 0.3946, 0.5279],\n",
            "        [0.3442, 0.6532, 0.6451],\n",
            "        [0.9523, 0.7694, 0.1862],\n",
            "        [0.1265, 0.3286, 0.4386],\n",
            "        [0.0906, 0.1307, 0.6013]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9v4GRlApmWP",
        "colab_type": "text"
      },
      "source": [
        "A tensor can have different datatypes;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pSbAFbE7p23C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "3dd238a6-9512-474c-feba-0397064a3339"
      },
      "source": [
        "x = torch.zeros(1, 3, dtype=torch.long)\n",
        "print(\"\\nx datatype:\",x.dtype)\n",
        "print(\"x: \", x)\n",
        "\n",
        "y = torch.zeros(1, 3, dtype=torch.float)\n",
        "print(\"\\ny datatype:\", y.dtype)\n",
        "print(\"y: \", y)\n",
        "\n",
        "z = torch.zeros(1, 3, dtype=torch.double)\n",
        "print(\"\\nz datatype:\",z.dtype)\n",
        "print(\"z: \", z)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "x datatype: torch.int64\n",
            "x:  tensor([[0, 0, 0]])\n",
            "\n",
            "y datatype: torch.float32\n",
            "y:  tensor([[0., 0., 0.]])\n",
            "\n",
            "z datatype: torch.float64\n",
            "z:  tensor([[0., 0., 0.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htdXJDfmrW7z",
        "colab_type": "text"
      },
      "source": [
        "A tensor can be constructed \n",
        "1. directly from data;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG2VP9mIrXva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59638de5-94bb-400f-ee09-c7e4457199c8"
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_moo-Ur0CF",
        "colab_type": "text"
      },
      "source": [
        "2. based on an existing tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXK9xWXqr_bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "94d207aa-7a71-4fad-8776-e50972aa7003"
      },
      "source": [
        "x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "y = torch.randn_like(x)                       #result will have the same size \n",
        "print(y)                                      \n",
        "\n",
        "z = torch.randn_like(y, dtype=torch.float)    # override dtype!\n",
        "print(z)  \n",
        "\n",
        "#get sizes of tensors;\n",
        "\n",
        "print(\"\\nSize of the tensors:\\n\",x.size(), y.size(), z.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-0.0491, -0.5335,  0.5258],\n",
            "        [ 0.9456, -0.0299,  0.5641]], dtype=torch.float64)\n",
            "tensor([[ 0.4084,  0.4161, -0.6045],\n",
            "        [ 2.5592, -0.4316, -0.4037]])\n",
            "\n",
            "Size of the tensors:\n",
            " torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v97cK6F_YXYY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vODYPzjYvAyb",
        "colab_type": "text"
      },
      "source": [
        "# **Tensor Operations:**\n",
        "\n",
        "Operations can be performed with different syntaxes. For addition;\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC3lJAJDvSVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f988254-e8e3-4c3c-c900-9cbd0fd11c0b"
      },
      "source": [
        "#syntax 1:\n",
        "x = torch.rand(2, 3)\n",
        "y = torch.randn_like(x)\n",
        "print(x + y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4309, 1.4328, 0.1483],\n",
            "        [1.0261, 1.1815, 1.6062]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBFY3Bdvvhbz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea6a6099-e598-4805-c5f2-07c21e18269b"
      },
      "source": [
        "#syntax 2:\n",
        "print(torch.add(x, y))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4309, 1.4328, 0.1483],\n",
            "        [1.0261, 1.1815, 1.6062]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjZPa1sZvrSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5052e20d-ba6a-44ca-8889-027c450b2cfb"
      },
      "source": [
        "#syntax 3: an output tensor as argument\n",
        "result = torch.empty(2, 3)\n",
        "torch.add(x, y, out=result)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4309, 1.4328, 0.1483],\n",
              "        [1.0261, 1.1815, 1.6062]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcAIOqwYv7W_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "59a050e5-1bd2-42af-ef9d-abe0c581649d"
      },
      "source": [
        "#syntax 4: in-place, post-fixed with an _\n",
        "print(y)\n",
        "\n",
        "y.add_(x)\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2219,  1.0630,  0.1108],\n",
            "        [ 0.2272,  0.6959,  0.8086]])\n",
            "tensor([[0.4309, 1.4328, 0.1483],\n",
            "        [1.0261, 1.1815, 1.6062]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAysQp8OxLgO",
        "colab_type": "text"
      },
      "source": [
        "NumPy-like indexing can be used for tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pPQbn-txPcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a645e742-b46f-4a57-990e-910792f7659a"
      },
      "source": [
        "print(x,\"\\n\")\n",
        "print(x[:, 1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6528, 0.3697, 0.0375],\n",
            "        [0.7989, 0.4855, 0.7976]]) \n",
            "\n",
            "tensor([0.3697, 0.4855])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMXNsgRbxbWg",
        "colab_type": "text"
      },
      "source": [
        "Resize/reshape a tensor with `torch.view`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rrCRqC7xx-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e81563b6-0114-425b-9441-1981c87a438b"
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnORYt7VyVNz",
        "colab_type": "text"
      },
      "source": [
        "To get the value as a Python number from a one element tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzaKj9r0yXN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "608771f2-a000-4411-a08a-13a365f03600"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.3720])\n",
            "-0.3720138370990753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "584dHoKDzOc9",
        "colab_type": "text"
      },
      "source": [
        "For 100+ Tensor operations you can visit;\n",
        "\n",
        "https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol-D5VGEzkG2",
        "colab_type": "text"
      },
      "source": [
        "# **Converting a Torch tensor to a NumPy array, and vice versa**\n",
        "\n",
        "Torch tensors and numpy arrays can be converted to each other. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgdtmEgE0GH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tensor to numpy\n",
        "x = torch.ones(5)\n",
        "print(x)\n",
        "y = x.numpy()\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8hKRHxs1h_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#numpy to tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skX8vcFY1CvO",
        "colab_type": "text"
      },
      "source": [
        "If underlying memory locations is on CPU, changing one will change the other; "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs9t5ed_1OHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.add_(1)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az4LUKuV1fvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIrV-7c_Ycnu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0T8AGbH12F-",
        "colab_type": "text"
      },
      "source": [
        "# **CUDA Tensors**\n",
        "\n",
        "Tensors can be moved onto any device using the `.to` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzWeMu4d2DKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run this cell only if CUDA is available\n",
        "# Use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_SvvIGUYeN3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCWblVgRAo6F",
        "colab_type": "text"
      },
      "source": [
        "# **`Autograd` Package**\n",
        "\n",
        " \n",
        "\n",
        "* Provides automatic differentiation for all operations on Tensors\n",
        "* A define-by-run framework (backprop is defined by how the code is run, and that every single iteration can be different)\n",
        "* If the attribute `.requires_grad`  of a tensor is set to as `True`, all opeations on the tensor will be tracked\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CR2vt1lC6ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrmO-TZyDspo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y was created as a result of an operation, so it has a grad_fn.\n",
        "print(y.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8uCi4ONDwjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIhuuDoxDoka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change an existing tensorâ€™s requires_grad flag in-place\n",
        "\n",
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z05jRG-2DR12",
        "colab_type": "text"
      },
      "source": [
        "* When the computation is finished, `.backward()` can be calle to compute all the gradients automatically (gadient will be accumulated into `.grad` attribute)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFM6_oJfEUej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGkAOH1YESUV",
        "colab_type": "text"
      },
      "source": [
        "* You can also stop autograd from tracking history by wrapping the code block in with torch.no_grad():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLLP63igFIhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1M_lELkFo6l",
        "colab_type": "text"
      },
      "source": [
        "* For more infomation: https://pytorch.org/docs/stable/autograd.html#function\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHlkLJNCF0LJ",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Networks (NN)**\n",
        "\n",
        "* NN can be construted with `torch.nn` package.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSYPwdhtGc1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfJ_jUwRQ_qo",
        "colab_type": "text"
      },
      "source": [
        "* nn depends on autograd to define models and differentiate them. \n",
        "* A typical training procedure for a neural network is as follows:\n",
        "\n",
        "    **i.** Define the neural network that has some learnable parameters (or weights). \n",
        "    \n",
        "    > The learnable parameters of a model are returned by net.parameters()\n",
        "\n",
        "  **ii.** Iterate over a dataset of inputs\n",
        "\n",
        "    **iii.** Process input through the network\n",
        "\n",
        "    **iv.** Compute the loss (how far is the output from being correct).\n",
        "\n",
        "    **v.** Propagate gradients back into the networkâ€™s parameters with loss.backward()\n",
        "\n",
        "    **vi.** Update the weights of the network. \n",
        "\n",
        "    > This can be performed by any of the various different update rules that are implemented in `torch.optim` package \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttXXwJEqQNu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATE INPUT, AND OUTPUT \n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "print(x.size(), y.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ro9m4BQlTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DEFINE NN:\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5eLJut3RT4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LEARNABLE PARAMETERS IN THE MODEL:\n",
        "params = list(model.parameters())\n",
        "print(\"Lenght of learnable parameters: \",len(params))\n",
        "print(\"Size of the first parameter: \", params[0].size()) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4RmEFGaTEz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WE WILL NEED A LOSS FUNCTION FOR STEP iv.\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "print(\"Loss function:\", loss_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLNQlNlbKNzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO UPDATE WEIGHTS, LETS USE ADAM \n",
        "# THAT IS ALREAY IMPLEMENTED IN torch.optim\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"Optimizer: \", optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIWsyb0zVzX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #TRAINING LOOP:\n",
        "for t in range(500):\n",
        "\n",
        "    # Forward pass: \n",
        "    # Feed input to the model \n",
        "    # and compute predicted.\n",
        " \n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    #with torch.no_grad():\n",
        "    #    for param in model.parameters():\n",
        "    #        param -= learning_rate * param.grad\n",
        "\n",
        "\n",
        "    # and update the weights.\n",
        "    \n",
        "    optimizer.step()            \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}